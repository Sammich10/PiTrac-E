/* SPDX-License-Identifier: GPL-2.0-only */
/*
 * Copyright (C) 2022-2025, Verdant Consultants, LLC.
 */

/**
 * @file ml_image_analyzer.hpp
 * @brief Machine Learning-based implementation framework for image analysis
 *
 * Provides a framework for integrating AI/ML approaches like YOLO, TensorFlow
 *Lite,
 * and other modern computer vision models alongside the existing OpenCV
 *implementation.
 * This enables experimentation with modern AI approaches while preserving the
 * sophisticated existing algorithms.
 */

#pragma once

#include "../domain/interfaces.hpp"
#include "../domain/analysis_results.hpp"
#include <memory>
#include <string>
#include <map>

namespace PiTrac::image_analysis::infrastructure::ml
{
// Forward declarations for ML frameworks
struct YOLOModel;
struct TensorFlowLiteModel;
struct PyTorchMobileModel;

/**
 * @brief Machine Learning-based analyzer for future AI integration
 *
 * This class provides the framework for integrating modern AI/ML approaches
 * for golf ball detection. It supports multiple ML frameworks and can be
 * configured to use different models at runtime.
 */
class MLImageAnalyzer : public domain::IImageAnalyzer
{
  public:
    /**
     * @brief Model types supported by the ML analyzer
     */
    enum class ModelType
    {
        YOLO_V5,        ///< YOLOv5 object detection model
        YOLO_V8,        ///< YOLOv8 object detection model
        TENSORFLOW_LITE,///< TensorFlow Lite mobile model
        PYTORCH_MOBILE, ///< PyTorch Mobile optimized model
        ONNX_RUNTIME    ///< ONNX Runtime cross-platform model
    };

    /**
     * @brief Constructor for ML-based image analyzer
     * @param model_type Type of ML model to use
     * @param model_path Path to the model file
     */
    explicit MLImageAnalyzer(ModelType model_type, const std::string &model_path);
    ~MLImageAnalyzer() override;

    // Domain interface implementation
    domain::TeedBallResult AnalyzeTeedBall(
        const domain::ImageBuffer &image,
        const std::optional<domain::BallPosition> &expected_position = std::nullopt
        ) override;

    domain::MovementResult DetectMovement(
        const std::vector<domain::ImageBuffer> &image_sequence,
        const domain::BallPosition &reference_ball_position
        ) override;

    domain::FlightAnalysisResult AnalyzeBallFlight(
        const domain::ImageBuffer &strobed_image,
        const domain::BallPosition &calibration_reference
        ) override;

    domain::TeedBallResult DetectBallReset(
        const domain::ImageBuffer &current_image,
        const domain::BallPosition &previous_ball_position
        ) override;

    // Analyzer metadata
    std::string GetAnalyzerName() const override;
    std::string GetVersion() const override
    {
        return "2.0.0-ml";
    }

    bool SupportsRealTime() const override;            // ML-specific
                                                       // configuration

    /**
     * @brief Load ML model from file
     * @param model_path Path to the model file
     * @return true if model loaded successfully, false otherwise
     */
    bool LoadModel(const std::string &model_path);

    /**
     * @brief Set confidence threshold for detections
     * @param threshold Minimum confidence (0.0-1.0) for valid detections
     */
    void SetConfidenceThreshold(double threshold);

    /**
     * @brief Set Non-Maximum Suppression threshold
     * @param threshold NMS threshold (0.0-1.0) for overlapping detections
     */
    void SetNMSThreshold(double threshold);

    /**
     * @brief Set input image size for model inference
     * @param width Target width in pixels
     * @param height Target height in pixels
     */
    void SetInputSize(int width, int height);

    /**
     * @brief Enable or disable GPU acceleration if available
     * @param enabled true to enable GPU acceleration, false for CPU only
     */
    void SetGPUAcceleration(bool enabled);

  private:
    ModelType model_type_;
    std::string model_path_;
    bool model_loaded_ = false;
    double confidence_threshold_ = 0.5;
    double nms_threshold_ = 0.4;
    int input_width_ = 640;
    int input_height_ = 640;
    bool gpu_acceleration_ = false;

    // Model-specific implementations
    std::unique_ptr<YOLOModel> yolo_model_;
    std::unique_ptr<TensorFlowLiteModel> tflite_model_;
    std::unique_ptr<PyTorchMobileModel> pytorch_model_;

    // Core ML processing methods
    std::vector<domain::BallPosition> RunInference(const cv::Mat &image);
    domain::TeedBallResult ClassifyBallState(const std::vector<domain::BallPosition> &detections);
    std::vector<cv::Point2f> EstimateMotionVectors(
        const std::vector<domain::ImageBuffer> &sequence);

    // Post-processing utilities
    std::vector<domain::BallPosition> FilterDetectionsByConfidence(
        const std::vector<domain::BallPosition> &detections) const;
    std::vector<domain::BallPosition> ApplyNonMaxSuppression(
        const std::vector<domain::BallPosition> &detections) const;

    // Model-specific inference
    std::vector<domain::BallPosition> RunYOLOInference(const cv::Mat &image);
    std::vector<domain::BallPosition> RunTensorFlowLiteInference(const cv::Mat &image);
    std::vector<domain::BallPosition> RunPyTorchMobileInference(const cv::Mat &image);

    // Preprocessing
    cv::Mat PreprocessImage(const cv::Mat &input) const;
    cv::Mat ResizeWithPadding(const cv::Mat &input, int target_width, int target_height) const;
    cv::Mat NormalizeImage(const cv::Mat &input) const;

    // Error handling
    domain::TeedBallResult CreateMLErrorResult(const std::string &error_message) const;
    domain::MovementResult CreateMLMovementErrorResult(const std::string &error_message) const;
    domain::FlightAnalysisResult CreateMLFlightErrorResult(const std::string &error_message) const;
};

/**
 * @brief Factory for ML-based analyzers
 */
class MLAnalyzerFactory : public domain::IImageAnalyzerFactory
{
  public:
    std::unique_ptr<domain::IImageAnalyzer> CreateAnalyzer(
        const std::string &analyzer_type = "yolo_v5"
        ) override;

    std::vector<std::string> GetAvailableAnalyzers() const override;
    bool IsAnalyzerAvailable(const std::string &analyzer_type) const override;

    // ML-specific factory methods
    std::unique_ptr<domain::IImageAnalyzer> CreateYOLOAnalyzer(
        const std::string &model_path,
        MLImageAnalyzer::ModelType version = MLImageAnalyzer::ModelType::YOLO_V5
        );

    std::unique_ptr<domain::IImageAnalyzer> CreateTensorFlowLiteAnalyzer(
        const std::string &model_path
        );

    std::unique_ptr<domain::IImageAnalyzer> CreatePyTorchMobileAnalyzer(
        const std::string &model_path
        );

  private:
    std::map<std::string, std::string> default_model_paths_;

    void InitializeDefaultModelPaths();
    bool IsModelFileValid(const std::string &model_path) const;
};

/**
 * @brief Hybrid analyzer that combines multiple approaches
 *
 * Uses multiple analyzers (e.g., OpenCV + ML) and combines results
 * for improved accuracy and reliability. Can fallback from ML to
 * traditional methods if ML inference fails.
 */
class HybridImageAnalyzer : public domain::IImageAnalyzer
{
  public:
    HybridImageAnalyzer(
        std::unique_ptr<domain::IImageAnalyzer> primary_analyzer,
        std::unique_ptr<domain::IImageAnalyzer> fallback_analyzer
        );

    ~HybridImageAnalyzer() override = default;

    // Domain interface implementation with hybrid logic
    domain::TeedBallResult AnalyzeTeedBall(
        const domain::ImageBuffer &image,
        const std::optional<domain::BallPosition> &expected_position = std::nullopt
        ) override;

    domain::MovementResult DetectMovement(
        const std::vector<domain::ImageBuffer> &image_sequence,
        const domain::BallPosition &reference_ball_position
        ) override;

    domain::FlightAnalysisResult AnalyzeBallFlight(
        const domain::ImageBuffer &strobed_image,
        const domain::BallPosition &calibration_reference
        ) override;

    domain::TeedBallResult DetectBallReset(
        const domain::ImageBuffer &current_image,
        const domain::BallPosition &previous_ball_position
        ) override;

    // Analyzer metadata
    std::string GetAnalyzerName() const override;
    std::string GetVersion() const override
    {
        return "1.0.0-hybrid";
    }

    bool SupportsRealTime() const override;

    // Hybrid-specific configuration
    void SetPrimaryConfidenceThreshold(double threshold);
    void SetFallbackMode(bool auto_fallback);
    void SetResultFusion(bool enable_fusion);

  private:
    std::unique_ptr<domain::IImageAnalyzer> primary_analyzer_;
    std::unique_ptr<domain::IImageAnalyzer> fallback_analyzer_;

    double primary_confidence_threshold_ = 0.6;
    bool auto_fallback_enabled_ = true;
    bool result_fusion_enabled_ = false;

    // Result combination strategies
    domain::TeedBallResult CombineTeedBallResults(
        const domain::TeedBallResult &primary,
        const domain::TeedBallResult &fallback) const;

    domain::MovementResult CombineMovementResults(
        const domain::MovementResult &primary,
        const domain::MovementResult &fallback) const;

    domain::FlightAnalysisResult CombineFlightResults(
        const domain::FlightAnalysisResult &primary,
        const domain::FlightAnalysisResult &fallback) const;

    // Helper methods
    bool ShouldUseFallback(double primary_confidence) const;
    domain::BallPosition FuseBallPositions(
        const domain::BallPosition &pos1,
        const domain::BallPosition &pos2,
        double weight1 = 0.5) const;
};

// Model interface abstractions (to be implemented based on actual ML
// frameworks)

/**
 * @brief Abstract interface for YOLO models
 */
struct YOLOModel
{
    virtual ~YOLOModel() = default;
    virtual bool LoadModel(const std::string &model_path) = 0;
    virtual std::vector<domain::BallPosition> Detect(const cv::Mat &image) = 0;
    virtual void SetConfidenceThreshold(double threshold) = 0;
    virtual void SetNMSThreshold(double threshold) = 0;
};

/**
 * @brief Abstract interface for TensorFlow Lite models
 */
struct TensorFlowLiteModel
{
    virtual ~TensorFlowLiteModel() = default;
    virtual bool LoadModel(const std::string &model_path) = 0;
    virtual std::vector<domain::BallPosition> Detect(const cv::Mat &image) = 0;
    virtual void SetInputSize(int width, int height) = 0;
};

/**
 * @brief Abstract interface for PyTorch Mobile models
 */
struct PyTorchMobileModel
{
    virtual ~PyTorchMobileModel() = default;
    virtual bool LoadModel(const std::string &model_path) = 0;
    virtual std::vector<domain::BallPosition> Detect(const cv::Mat &image) = 0;
    virtual void SetGPUAcceleration(bool enabled) = 0;
};
} // namespace PiTrac::image_analysis::infrastructure::ml
